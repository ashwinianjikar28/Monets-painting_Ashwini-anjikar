{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip uninstall tensorflow -y\n# !pip install tensorflow==2.15.0\n# !pip install tensorflow-addons","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:53:59.754375Z","iopub.execute_input":"2025-04-05T08:53:59.754667Z","iopub.status.idle":"2025-04-05T08:53:59.758052Z","shell.execute_reply.started":"2025-04-05T08:53:59.754644Z","shell.execute_reply":"2025-04-05T08:53:59.757220Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport cv2\nimport os\nfrom tensorflow.keras import layers, Model\nfrom PIL import Image\nimport zipfile\n\n# TPU setup (if available)\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nprint(tf.__version__)\n\n# Define directories\nmonet_jpg_directory = '/kaggle/input/gan-getting-started/monet_jpg'\nphoto_jpg_directory = '/kaggle/input/gan-getting-started/photo_jpg'\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:53:59.760707Z","iopub.execute_input":"2025-04-05T08:53:59.760974Z","iopub.status.idle":"2025-04-05T08:53:59.774960Z","shell.execute_reply.started":"2025-04-05T08:53:59.760947Z","shell.execute_reply":"2025-04-05T08:53:59.774110Z"}},"outputs":[{"name":"stdout","text":"Number of replicas: 1\n2.15.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Function to get image paths\ndef getImagePaths(path):\n    image_names = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            fullpath = os.path.join(dirname, filename)\n            image_names.append(fullpath)\n    return image_names\n\nmonet_images_path = getImagePaths(monet_jpg_directory)\nphoto_images_path = getImagePaths(photo_jpg_directory)\n\nprint(f\"Number of Monet images: {len(monet_images_path)}\")\nprint(f\"Number of Photo images: {len(photo_images_path)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:53:59.775892Z","iopub.execute_input":"2025-04-05T08:53:59.776413Z","iopub.status.idle":"2025-04-05T08:54:01.662037Z","shell.execute_reply.started":"2025-04-05T08:53:59.776381Z","shell.execute_reply":"2025-04-05T08:54:01.661115Z"}},"outputs":[{"name":"stdout","text":"Number of Monet images: 300\nNumber of Photo images: 7038\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Image preprocessing function\ndef preprocess_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = (image / 127.5) - 1  # Normalize to [-1, 1]\n    return image\n\n# Create TensorFlow datasets\nmonet_ds = tf.data.Dataset.from_tensor_slices(monet_images_path).map(preprocess_image, num_parallel_calls=AUTOTUNE)\nphoto_ds = tf.data.Dataset.from_tensor_slices(photo_images_path).map(preprocess_image, num_parallel_calls=AUTOTUNE)\n\n# Batch and shuffle the datasets\nBATCH_SIZE = 1  # Reverted to 1 for CycleGAN standard\nmonet_ds = monet_ds.cache().shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\nphoto_ds = photo_ds.cache().shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n\n# Downsampling block\ndef downsample(filters, size, apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n                             kernel_initializer=initializer, use_bias=False))\n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization())\n    result.add(layers.LeakyReLU())\n    return result\n\n# Upsampling block\ndef upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n                                      kernel_initializer=initializer, use_bias=False))\n    result.add(tfa.layers.InstanceNormalization())\n    if apply_dropout:\n        result.add(layers.Dropout(0.5))\n    result.add(layers.ReLU())\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:01.663857Z","iopub.execute_input":"2025-04-05T08:54:01.664242Z","iopub.status.idle":"2025-04-05T08:54:01.772106Z","shell.execute_reply.started":"2025-04-05T08:54:01.664211Z","shell.execute_reply":"2025-04-05T08:54:01.771245Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Generator model with additional residual blocks\ndef Generator():\n    inputs = layers.Input(shape=[256, 256, 3])\n    \n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False),  # (bs, 128, 128, 64)\n        downsample(128, 4),  # (bs, 64, 64, 128)\n        downsample(256, 4),  # (bs, 32, 32, 256)\n        downsample(512, 4),  # (bs, 16, 16, 512)\n        downsample(512, 4),  # (bs, 8, 8, 512)\n        downsample(512, 4),  # (bs, 4, 4, 512)\n        downsample(512, 4),  # (bs, 2, 2, 512)\n        downsample(512, 4),  # (bs, 1, 1, 512)\n    ]\n    \n    # Residual blocks for better feature learning\n    res_blocks = [layers.Conv2D(512, 3, strides=1, padding='same', activation='relu', kernel_initializer=tf.random_normal_initializer(0., 0.02)) for _ in range(2)]\n    \n    up_stack = [\n        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 512)\n        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 512)\n        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 512)\n        upsample(512, 4),  # (bs, 16, 16, 512)\n        upsample(256, 4),  # (bs, 32, 32, 256)\n        upsample(128, 4),  # (bs, 64, 64, 128)\n        upsample(64, 4),  # (bs, 128, 128, 64)\n    ]\n    \n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = layers.Conv2DTranspose(3, 4, strides=2, padding='same',\n                                  kernel_initializer=initializer, activation='tanh')  # (bs, 256, 256, 3)\n    \n    x = inputs\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n    \n    # Apply residual blocks\n    for res in res_blocks:\n        x = res(x)\n    \n    skips = reversed(skips[:-1])\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = layers.Concatenate()([x, skip])\n    \n    x = last(x)\n    return Model(inputs=inputs, outputs=x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:01.773189Z","iopub.execute_input":"2025-04-05T08:54:01.773474Z","iopub.status.idle":"2025-04-05T08:54:01.783675Z","shell.execute_reply.started":"2025-04-05T08:54:01.773447Z","shell.execute_reply":"2025-04-05T08:54:01.782753Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Discriminator model\ndef Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n    x = inp\n    \n    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n    down2 = downsample(128, 4)(down1)  # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n    \n    zero_pad1 = layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n    conv = layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n    norm1 = tfa.layers.InstanceNormalization()(conv)\n    leaky_relu = layers.LeakyReLU()(norm1)\n    zero_pad2 = layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n    last = layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n    \n    return Model(inputs=inp, outputs=last)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:01.784660Z","iopub.execute_input":"2025-04-05T08:54:01.784896Z","iopub.status.idle":"2025-04-05T08:54:01.800820Z","shell.execute_reply.started":"2025-04-05T08:54:01.784877Z","shell.execute_reply":"2025-04-05T08:54:01.799915Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Instantiate models\nwith strategy.scope():\n    monet_generator = Generator()\n    photo_generator = Generator()\n    monet_discriminator = Discriminator()\n    photo_discriminator = Discriminator()\n\n# Loss functions\nwith strategy.scope():\n    loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n\ndef discriminator_loss(real, generated):\n    real_loss = tf.reduce_mean(loss_obj(tf.ones_like(real), real))\n    generated_loss = tf.reduce_mean(loss_obj(tf.zeros_like(generated), generated))\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss * 0.5\n\ndef generator_loss(generated):\n    return tf.reduce_mean(loss_obj(tf.ones_like(generated), generated))\n\ndef calc_cycle_loss(real_image, cycled_image, LAMBDA=10):  # Standard LAMBDA\n    l1_loss = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    l2_loss = tf.reduce_mean(tf.square(real_image - cycled_image))\n    return LAMBDA * (0.9 * l1_loss + 0.1 * l2_loss)  # Mix L1 and L2\n\ndef identity_loss(real_image, same_image, LAMBDA=5):  # Reduced LAMBDA to avoid overfitting\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss\n\n# Learning rate scheduler\ninitial_learning_rate = 2e-4\nlr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n    boundaries=[50 * (len(monet_images_path) // BATCH_SIZE), 75 * (len(monet_images_path) // BATCH_SIZE)],\n    values=[initial_learning_rate, initial_learning_rate * 0.1, initial_learning_rate * 0.01]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:01.801568Z","iopub.execute_input":"2025-04-05T08:54:01.801795Z","iopub.status.idle":"2025-04-05T08:54:04.363770Z","shell.execute_reply.started":"2025-04-05T08:54:01.801772Z","shell.execute_reply":"2025-04-05T08:54:04.363095Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Optimizers with gradient clipping\nwith strategy.scope():\n    monet_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n    photo_generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n    monet_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n    photo_discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.5, clipnorm=1.0)\n\n@tf.function\ndef train_step(real_monet, real_photo):\n    with tf.GradientTape(persistent=True) as tape:\n        fake_monet = monet_generator(real_photo, training=True)\n        cycled_photo = photo_generator(fake_monet, training=True)\n        fake_photo = photo_generator(real_monet, training=True)\n        cycled_monet = monet_generator(fake_photo, training=True)\n        same_monet = monet_generator(real_monet, training=True)\n        same_photo = photo_generator(real_photo, training=True)\n        disc_real_monet = monet_discriminator(real_monet, training=True)\n        disc_real_photo = photo_discriminator(real_photo, training=True)\n        disc_fake_monet = monet_discriminator(fake_monet, training=True)\n        disc_fake_photo = photo_discriminator(fake_photo, training=True)\n        monet_gen_loss = generator_loss(disc_fake_monet)\n        photo_gen_loss = generator_loss(disc_fake_photo)\n        total_cycle_loss = calc_cycle_loss(real_monet, cycled_monet) + calc_cycle_loss(real_photo, cycled_photo)\n        total_monet_gen_loss = monet_gen_loss + total_cycle_loss + identity_loss(real_monet, same_monet)\n        total_photo_gen_loss = photo_gen_loss + total_cycle_loss + identity_loss(real_photo, same_photo)\n        monet_disc_loss = discriminator_loss(disc_real_monet, disc_fake_monet)\n        photo_disc_loss = discriminator_loss(disc_real_photo, disc_fake_photo)\n    \n    monet_generator_gradients = tape.gradient(total_monet_gen_loss, monet_generator.trainable_variables)\n    photo_generator_gradients = tape.gradient(total_photo_gen_loss, photo_generator.trainable_variables)\n    monet_discriminator_gradients = tape.gradient(monet_disc_loss, monet_discriminator.trainable_variables)\n    photo_discriminator_gradients = tape.gradient(photo_disc_loss, photo_discriminator.trainable_variables)\n    \n    monet_generator_optimizer.apply_gradients(zip(monet_generator_gradients, monet_generator.trainable_variables))\n    photo_generator_optimizer.apply_gradients(zip(photo_generator_gradients, photo_generator.trainable_variables))\n    monet_discriminator_optimizer.apply_gradients(zip(monet_discriminator_gradients, monet_discriminator.trainable_variables))\n    photo_discriminator_optimizer.apply_gradients(zip(photo_discriminator_gradients, photo_discriminator.trainable_variables))\n    \n    return total_monet_gen_loss, total_photo_gen_loss, monet_disc_loss, photo_disc_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:55:52.203371Z","iopub.execute_input":"2025-04-05T08:55:52.203669Z","iopub.status.idle":"2025-04-05T08:55:52.806847Z","shell.execute_reply.started":"2025-04-05T08:55:52.203648Z","shell.execute_reply":"2025-04-05T08:55:52.806114Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Training loop\nEPOCHS = 150\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    total_monet_gen_loss = 0\n    total_photo_gen_loss = 0\n    total_monet_disc_loss = 0\n    total_photo_disc_loss = 0\n    n_batches = 0\n    \n    for real_monet, real_photo in tf.data.Dataset.zip((monet_ds, photo_ds)):\n        monet_gen_loss, photo_gen_loss, monet_disc_loss, photo_disc_loss = train_step(real_monet, real_photo)\n        total_monet_gen_loss += monet_gen_loss.numpy()\n        total_photo_gen_loss += photo_gen_loss.numpy()\n        total_monet_disc_loss += monet_disc_loss.numpy()\n        total_photo_disc_loss += photo_disc_loss.numpy()\n        n_batches += 1\n    \n    avg_monet_gen_loss = total_monet_gen_loss / n_batches\n    avg_photo_gen_loss = total_photo_gen_loss / n_batches\n    avg_monet_disc_loss = total_monet_disc_loss / n_batches\n    avg_photo_disc_loss = total_photo_disc_loss / n_batches\n    \n    print(f\"Avg Monet Gen Loss: {avg_monet_gen_loss:.4f}, Avg Photo Gen Loss: {avg_photo_gen_loss:.4f}, \"\n          f\"Avg Monet Disc Loss: {avg_monet_disc_loss:.4f}, Avg Photo Disc Loss: {avg_photo_disc_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:55:56.831358Z","iopub.execute_input":"2025-04-05T08:55:56.831643Z","execution_failed":"2025-04-05T10:00:07.896Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/150\nAvg Monet Gen Loss: 4.7156, Avg Photo Gen Loss: 4.6965, Avg Monet Disc Loss: 0.7100, Avg Photo Disc Loss: 0.7131\nEpoch 2/150\nAvg Monet Gen Loss: 3.1608, Avg Photo Gen Loss: 3.1073, Avg Monet Disc Loss: 0.6705, Avg Photo Disc Loss: 0.6789\nEpoch 3/150\nAvg Monet Gen Loss: 2.9297, Avg Photo Gen Loss: 2.9168, Avg Monet Disc Loss: 0.6699, Avg Photo Disc Loss: 0.6769\nEpoch 4/150\nAvg Monet Gen Loss: 2.8040, Avg Photo Gen Loss: 2.7974, Avg Monet Disc Loss: 0.6596, Avg Photo Disc Loss: 0.6668\nEpoch 5/150\nAvg Monet Gen Loss: 2.7098, Avg Photo Gen Loss: 2.6947, Avg Monet Disc Loss: 0.6636, Avg Photo Disc Loss: 0.6713\nEpoch 6/150\nAvg Monet Gen Loss: 2.5534, Avg Photo Gen Loss: 2.5621, Avg Monet Disc Loss: 0.6633, Avg Photo Disc Loss: 0.6640\nEpoch 7/150\nAvg Monet Gen Loss: 2.4769, Avg Photo Gen Loss: 2.4542, Avg Monet Disc Loss: 0.6644, Avg Photo Disc Loss: 0.6633\nEpoch 8/150\nAvg Monet Gen Loss: 2.4410, Avg Photo Gen Loss: 2.4175, Avg Monet Disc Loss: 0.6554, Avg Photo Disc Loss: 0.6644\nEpoch 9/150\nAvg Monet Gen Loss: 2.4070, Avg Photo Gen Loss: 2.4054, Avg Monet Disc Loss: 0.6613, Avg Photo Disc Loss: 0.6653\nEpoch 10/150\nAvg Monet Gen Loss: 2.3627, Avg Photo Gen Loss: 2.3498, Avg Monet Disc Loss: 0.6603, Avg Photo Disc Loss: 0.6628\nEpoch 11/150\nAvg Monet Gen Loss: 2.3616, Avg Photo Gen Loss: 2.3721, Avg Monet Disc Loss: 0.6555, Avg Photo Disc Loss: 0.6557\nEpoch 12/150\nAvg Monet Gen Loss: 2.3029, Avg Photo Gen Loss: 2.2960, Avg Monet Disc Loss: 0.6551, Avg Photo Disc Loss: 0.6632\nEpoch 13/150\nAvg Monet Gen Loss: 2.3093, Avg Photo Gen Loss: 2.3091, Avg Monet Disc Loss: 0.6574, Avg Photo Disc Loss: 0.6607\nEpoch 14/150\nAvg Monet Gen Loss: 2.2655, Avg Photo Gen Loss: 2.2684, Avg Monet Disc Loss: 0.6598, Avg Photo Disc Loss: 0.6625\nEpoch 15/150\nAvg Monet Gen Loss: 2.2392, Avg Photo Gen Loss: 2.2758, Avg Monet Disc Loss: 0.6656, Avg Photo Disc Loss: 0.6562\nEpoch 16/150\nAvg Monet Gen Loss: 2.2316, Avg Photo Gen Loss: 2.2367, Avg Monet Disc Loss: 0.6627, Avg Photo Disc Loss: 0.6546\nEpoch 17/150\nAvg Monet Gen Loss: 2.2672, Avg Photo Gen Loss: 2.2911, Avg Monet Disc Loss: 0.6565, Avg Photo Disc Loss: 0.6471\nEpoch 18/150\nAvg Monet Gen Loss: 2.2968, Avg Photo Gen Loss: 2.3623, Avg Monet Disc Loss: 0.6609, Avg Photo Disc Loss: 0.6526\nEpoch 19/150\nAvg Monet Gen Loss: 2.2337, Avg Photo Gen Loss: 2.2837, Avg Monet Disc Loss: 0.6700, Avg Photo Disc Loss: 0.6606\nEpoch 20/150\nAvg Monet Gen Loss: 2.1870, Avg Photo Gen Loss: 2.2563, Avg Monet Disc Loss: 0.6703, Avg Photo Disc Loss: 0.6543\nEpoch 21/150\nAvg Monet Gen Loss: 2.2332, Avg Photo Gen Loss: 2.3039, Avg Monet Disc Loss: 0.6704, Avg Photo Disc Loss: 0.6514\nEpoch 22/150\nAvg Monet Gen Loss: 2.1854, Avg Photo Gen Loss: 2.2522, Avg Monet Disc Loss: 0.6694, Avg Photo Disc Loss: 0.6502\nEpoch 23/150\nAvg Monet Gen Loss: 2.1581, Avg Photo Gen Loss: 2.2418, Avg Monet Disc Loss: 0.6700, Avg Photo Disc Loss: 0.6570\nEpoch 24/150\nAvg Monet Gen Loss: 2.1652, Avg Photo Gen Loss: 2.2187, Avg Monet Disc Loss: 0.6685, Avg Photo Disc Loss: 0.6518\nEpoch 25/150\nAvg Monet Gen Loss: 2.1284, Avg Photo Gen Loss: 2.2247, Avg Monet Disc Loss: 0.6761, Avg Photo Disc Loss: 0.6577\nEpoch 26/150\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Display generated images\ndef display_generated_images(photo_ds, num_images=5):\n    plt.figure(figsize=(15, 5))\n    for i, photo in enumerate(photo_ds.take(num_images)):\n        fake_monet = monet_generator(photo, training=False)\n        fake_monet = (fake_monet[0] * 0.5 + 0.5)\n        photo = (photo[0] * 0.5 + 0.5)\n        \n        plt.subplot(2, num_images, i + 1)\n        plt.imshow(photo)\n        plt.title(\"Original Photo\")\n        plt.axis('off')\n        \n        plt.subplot(2, num_images, i + 1 + num_images)\n        plt.imshow(fake_monet)\n        plt.title(\"Monet Style\")\n        plt.axis('off')\n    plt.show()\n\ndisplay_generated_images(photo_ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:05.198740Z","iopub.status.idle":"2025-04-05T08:54:05.199023Z","shell.execute_reply":"2025-04-05T08:54:05.198877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate and save images\noutput_dir = '/kaggle/working/images'\nos.makedirs(output_dir, exist_ok=True)\n\ndef generate_and_save_images(photo_ds, monet_generator, num_images=7000):\n    count = 0\n    for photo in photo_ds:\n        if count >= num_images:\n            break\n        fake_monet = monet_generator(photo, training=False)\n        fake_monet = (fake_monet[0] * 0.5 + 0.5)\n        fake_monet = tf.clip_by_value(fake_monet, 0, 1)\n        fake_monet = (fake_monet * 255).numpy().astype(np.uint8)\n        img = Image.fromarray(fake_monet)\n        img.save(os.path.join(output_dir, f'monet_{count:04d}.jpg'), quality=95)  # Higher quality JPEG\n        count += 1\n    print(f\"Generated {count} Monet-style images.\")\n\ngenerate_and_save_images(photo_ds, monet_generator, num_images=7000)\n\nzip_filename = '/kaggle/working/images.zip'\nwith zipfile.ZipFile(zip_filename, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(output_dir):\n        for file in files:\n            zipf.write(os.path.join(root, file), arcname=file)\n\nprint(f\"Submission file created: {zip_filename}\")\nprint(f\"Total images zipped: {len(os.listdir(output_dir))}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:54:05.199850Z","iopub.status.idle":"2025-04-05T08:54:05.200279Z","shell.execute_reply":"2025-04-05T08:54:05.200076Z"}},"outputs":[],"execution_count":null}]}